{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9774351,"sourceType":"datasetVersion","datasetId":5987382}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install --upgrade nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:57:11.385341Z","iopub.execute_input":"2024-11-05T06:57:11.385768Z","iopub.status.idle":"2024-11-05T06:57:11.390662Z","shell.execute_reply.started":"2024-11-05T06:57:11.385696Z","shell.execute_reply":"2024-11-05T06:57:11.389669Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk import ngrams\nimport re\nfrom collections import defaultdict, Counter\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:57:12.378767Z","iopub.execute_input":"2024-11-05T06:57:12.379519Z","iopub.status.idle":"2024-11-05T06:57:13.919824Z","shell.execute_reply.started":"2024-11-05T06:57:12.379478Z","shell.execute_reply":"2024-11-05T06:57:13.918846Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel, Trainer, TrainingArguments, EarlyStoppingCallback\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:57:17.082164Z","iopub.execute_input":"2024-11-05T06:57:17.082679Z","iopub.status.idle":"2024-11-05T06:57:35.236426Z","shell.execute_reply.started":"2024-11-05T06:57:17.082641Z","shell.execute_reply":"2024-11-05T06:57:35.235610Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:43:00.632084Z","iopub.execute_input":"2024-11-05T09:43:00.632497Z","iopub.status.idle":"2024-11-05T09:43:00.640530Z","shell.execute_reply.started":"2024-11-05T09:43:00.632459Z","shell.execute_reply":"2024-11-05T09:43:00.639311Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/cyber-crime/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/cyber-crime/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:24.507558Z","iopub.execute_input":"2024-11-05T09:21:24.508293Z","iopub.status.idle":"2024-11-05T09:21:25.244836Z","shell.execute_reply.started":"2024-11-05T09:21:24.508245Z","shell.execute_reply":"2024-11-05T09:21:25.243841Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"df_train = train.copy()\ndf_train = df_train.dropna(subset=[\"crimeaditionalinfo\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:25.246546Z","iopub.execute_input":"2024-11-05T09:21:25.246877Z","iopub.status.idle":"2024-11-05T09:21:25.517892Z","shell.execute_reply.started":"2024-11-05T09:21:25.246844Z","shell.execute_reply":"2024-11-05T09:21:25.516763Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"df_test = test.copy()\ndf_test = df_test.dropna(subset=['crimeaditionalinfo'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:25.519822Z","iopub.execute_input":"2024-11-05T09:21:25.520591Z","iopub.status.idle":"2024-11-05T09:21:25.638429Z","shell.execute_reply.started":"2024-11-05T09:21:25.520543Z","shell.execute_reply":"2024-11-05T09:21:25.637386Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Ensure you have downloaded NLTK's punkt tokenizer\nnltk.download('punkt')\nnltk.download('punkt_tab')\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:25.873646Z","iopub.execute_input":"2024-11-05T09:21:25.874384Z","iopub.status.idle":"2024-11-05T09:21:26.013339Z","shell.execute_reply.started":"2024-11-05T09:21:25.874344Z","shell.execute_reply":"2024-11-05T09:21:26.012423Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:26.352305Z","iopub.execute_input":"2024-11-05T09:21:26.353232Z","iopub.status.idle":"2024-11-05T09:21:26.358837Z","shell.execute_reply.started":"2024-11-05T09:21:26.353187Z","shell.execute_reply":"2024-11-05T09:21:26.357895Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def pre_clean_text(text):\n    text = text.lower()  # Lowercase conversion\n    text = re.sub(r'\\b[A-Z]{2,4}\\b', ' ', text)  # Remove abbreviations identified earlier\n    return text\n\ndf_train['cleaned_text'] = df_train['crimeaditionalinfo'].apply(pre_clean_text)\ndf_test['cleaned_text'] = df_test['crimeaditionalinfo'].apply(pre_clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:27.399259Z","iopub.execute_input":"2024-11-05T09:21:27.400265Z","iopub.status.idle":"2024-11-05T09:21:29.641956Z","shell.execute_reply.started":"2024-11-05T09:21:27.400220Z","shell.execute_reply":"2024-11-05T09:21:29.641122Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"abbreviation_dict = {\n    \"atm\": \"automated teller machine\",\n    \"id\": \"identification\",\n    \"dr\": \"doctor\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:29.643794Z","iopub.execute_input":"2024-11-05T09:21:29.644127Z","iopub.status.idle":"2024-11-05T09:21:29.649258Z","shell.execute_reply.started":"2024-11-05T09:21:29.644095Z","shell.execute_reply":"2024-11-05T09:21:29.648403Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def clean_text(text):\n    # Standardize abbreviations\n    for abbr, full_form in abbreviation_dict.items():\n        text = re.sub(r'\\b' + re.escape(abbr) + r'\\b', full_form, text)\n    # Remove HTML tags, punctuation, and excessive whitespace\n    text = re.sub(r'<[^>]+>', ' ', text)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\ndf_train['cleaned_text'] = df_train['cleaned_text'].apply(clean_text)\ndf_test['cleaned_text'] = df_test['cleaned_text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:29.650509Z","iopub.execute_input":"2024-11-05T09:21:29.650893Z","iopub.status.idle":"2024-11-05T09:21:41.325964Z","shell.execute_reply.started":"2024-11-05T09:21:29.650850Z","shell.execute_reply":"2024-11-05T09:21:41.325154Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def normalize_tokenize(text):\n    # Convert to lowercase, remove stop words\n    words = [word for word in nltk.word_tokenize(text.lower()) if word.isalpha() and word not in stop_words]\n    return words\n\ndf_train['tokens'] = df_train['cleaned_text'].apply(normalize_tokenize)\ndf_test['tokens'] = df_test['cleaned_text'].apply(normalize_tokenize)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:21:41.327900Z","iopub.execute_input":"2024-11-05T09:21:41.328213Z","iopub.status.idle":"2024-11-05T09:22:49.481863Z","shell.execute_reply.started":"2024-11-05T09:21:41.328179Z","shell.execute_reply":"2024-11-05T09:22:49.481021Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"df_train['lemmatized_tokens'] = df_train['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\ndf_test['lemmatized_tokens'] = df_test['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:22:49.483086Z","iopub.execute_input":"2024-11-05T09:22:49.483473Z","iopub.status.idle":"2024-11-05T09:23:25.520380Z","shell.execute_reply.started":"2024-11-05T09:22:49.483431Z","shell.execute_reply":"2024-11-05T09:23:25.519328Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"custom_dictionary = {\n    \"fraud\": [\"scam\", \"deceit\", \"trickery\"],\n    \"theft\": [\"stealing\", \"robbery\", \"burglary\"]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:23:25.521768Z","iopub.execute_input":"2024-11-05T09:23:25.522520Z","iopub.status.idle":"2024-11-05T09:23:25.527656Z","shell.execute_reply.started":"2024-11-05T09:23:25.522468Z","shell.execute_reply":"2024-11-05T09:23:25.526787Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def tag_domain_terms(tokens, custom_dict):\n    tagged_terms = []\n    for word in tokens:\n        for key, synonyms in custom_dict.items():\n            if word in synonyms:\n                tagged_terms.append(key)  # Replace synonym with standard term\n            else:\n                tagged_terms.append(word)\n    return tagged_terms\n\ndf_train['tagged_terms'] = df_train['lemmatized_tokens'].apply(lambda x: tag_domain_terms(x, custom_dictionary))\ndf_test['tagged_terms'] = df_test['lemmatized_tokens'].apply(lambda x: tag_domain_terms(x, custom_dictionary))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:23:25.528990Z","iopub.execute_input":"2024-11-05T09:23:25.529443Z","iopub.status.idle":"2024-11-05T09:23:29.432098Z","shell.execute_reply.started":"2024-11-05T09:23:25.529399Z","shell.execute_reply":"2024-11-05T09:23:29.431014Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"df_test['text'] = df_test['lemmatized_tokens'].apply(lambda x: ' '.join(x))\ndf_test['labels'] = list(zip(df_test['category'], df_test['sub_category']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:23:29.435193Z","iopub.execute_input":"2024-11-05T09:23:29.435608Z","iopub.status.idle":"2024-11-05T09:23:29.527696Z","shell.execute_reply.started":"2024-11-05T09:23:29.435562Z","shell.execute_reply":"2024-11-05T09:23:29.526940Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"df_train['text'] = df_train['lemmatized_tokens'].apply(lambda x: ' '.join(x))  # Join tokens into a single string\ndf_train['labels'] = list(zip(df_train['category'], df_train['sub_category']))\n\n# Encode Labels\nle_category = LabelEncoder()\nle_sub_category = LabelEncoder()\ndf_train['category'] = le_category.fit_transform(df_train['category'])\ndf_train['sub_category'] = le_sub_category.fit_transform(df_train['sub_category'])\n\n# Train-Validation Split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df_train['text'].tolist(),\n    df_train[['category', 'sub_category']].values.tolist(),\n    test_size=0.2,\n    random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:23:29.528744Z","iopub.execute_input":"2024-11-05T09:23:29.529041Z","iopub.status.idle":"2024-11-05T09:23:30.911231Z","shell.execute_reply.started":"2024-11-05T09:23:29.529010Z","shell.execute_reply":"2024-11-05T09:23:30.910276Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Load Tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# 2. Custom Dataset Class for Multi-Output Labels\nclass CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        labels = torch.tensor(self.labels[idx], dtype=torch.long)\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors=\"pt\"\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': labels\n        }\n\n# Prepare datasets\ntrain_dataset = CustomDataset(train_texts, train_labels, tokenizer)\nval_dataset = CustomDataset(val_texts, val_labels, tokenizer)\n\n# 3. Define Custom BERT Model for Multi-Output Classification\nclass MultiOutputBERT(nn.Module):\n    def __init__(self, num_labels1, num_labels2):\n        super(MultiOutputBERT, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.drop = nn.Dropout(p=0.2)  # Lower dropout rate for better information retention\n        self.fc_category = nn.Linear(self.bert.config.hidden_size, num_labels1)\n        self.fc_sub_category = nn.Linear(self.bert.config.hidden_size, num_labels2)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = self.drop(outputs.pooler_output)\n        category_logits = self.fc_category(pooled_output)\n        sub_category_logits = self.fc_sub_category(pooled_output)\n\n        # Calculate loss if labels are provided\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss_category = loss_fct(category_logits, labels[:, 0])\n            loss_sub_category = loss_fct(sub_category_logits, labels[:, 1])\n            loss = loss_category + loss_sub_category\n        return (loss, category_logits, sub_category_logits)\n\n# 4. Initialize Model\nnum_categories = df_train['category'].nunique()\nnum_sub_categories = df_train['sub_category'].nunique()\nmodel = MultiOutputBERT(num_labels1=num_categories, num_labels2=num_sub_categories)\n\n# 5. Training Arguments with Optimizations for Space, Speed, and Accuracy\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=5,  # Increased for better training\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    warmup_steps=500,\n    weight_decay=0.05,\n    learning_rate=2e-5,\n    lr_scheduler_type='cosine',  # Smoother learning rate decay\n    logging_dir='./logs',\n    logging_steps=100,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",  # Match save strategy to evaluation strategy\n    fp16=True,  # Mixed precision for faster computation\n    gradient_accumulation_steps=4,  # Accumulate to increase batch size effectively\n    save_total_limit=1,  # Keep only the latest checkpoint to save space\n    load_best_model_at_end=True  # Load best model after early stopping\n)\n\n# 6. Trainer Setup with Early Stopping\nclass MultiLabelTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs, labels=labels)\n        loss = outputs[0]\n        return (loss, outputs) if return_outputs else loss\n\ntrainer = MultiLabelTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Stop early if no improvement\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T07:04:17.809144Z","iopub.execute_input":"2024-11-05T07:04:17.809559Z","iopub.status.idle":"2024-11-05T07:04:18.790266Z","shell.execute_reply.started":"2024-11-05T07:04:17.809517Z","shell.execute_reply":"2024-11-05T07:04:18.789291Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T07:04:22.826607Z","iopub.execute_input":"2024-11-05T07:04:22.827015Z","iopub.status.idle":"2024-11-05T08:50:36.577559Z","shell.execute_reply.started":"2024-11-05T07:04:22.826978Z","shell.execute_reply":"2024-11-05T08:50:36.576630Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='11705' max='11705' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [11705/11705 1:46:11, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2.185200</td>\n      <td>2.081829</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.978800</td>\n      <td>2.006339</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.795900</td>\n      <td>2.003662</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.519600</td>\n      <td>2.126788</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=11705, training_loss=1.9244757525587834, metrics={'train_runtime': 6372.6248, 'train_samples_per_second': 58.792, 'train_steps_per_second': 1.837, 'total_flos': 0.0, 'train_loss': 1.9244757525587834, 'epoch': 4.998398633500587})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"eval_results = trainer.evaluate()\nprint(f\"Validation Loss: {eval_results['eval_loss']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T08:55:24.530046Z","iopub.execute_input":"2024-11-05T08:55:24.530700Z","iopub.status.idle":"2024-11-05T08:57:24.801460Z","shell.execute_reply.started":"2024-11-05T08:55:24.530659Z","shell.execute_reply":"2024-11-05T08:57:24.800524Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Validation Loss: 2.003661632537842\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"torch.save(model.state_dict(), \"multi_output_bert_state_dict.pth\")\n\n# Save the tokenizer using Hugging Face's save_pretrained method\ntokenizer.save_pretrained(\"best_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T08:59:06.636426Z","iopub.execute_input":"2024-11-05T08:59:06.636824Z","iopub.status.idle":"2024-11-05T08:59:07.302678Z","shell.execute_reply.started":"2024-11-05T08:59:06.636788Z","shell.execute_reply":"2024-11-05T08:59:07.301744Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"('best_model/tokenizer_config.json',\n 'best_model/special_tokens_map.json',\n 'best_model/vocab.txt',\n 'best_model/added_tokens.json')"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"predictions = trainer.predict(val_dataset)\npred_logits = predictions.predictions\n\n# Step 2: Separate logits for category and sub_category\ncategory_logits = pred_logits[0]  # First set of logits for category\nsub_category_logits = pred_logits[1]  # Second set of logits for sub_category\n\n# Step 3: Get the predicted labels by taking the argmax of logits\ncategory_preds = category_logits.argmax(axis=1)\nsub_category_preds = sub_category_logits.argmax(axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T08:59:29.064248Z","iopub.execute_input":"2024-11-05T08:59:29.064628Z","iopub.status.idle":"2024-11-05T09:01:35.407128Z","shell.execute_reply.started":"2024-11-05T08:59:29.064594Z","shell.execute_reply":"2024-11-05T09:01:35.406196Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(category_preds, [val_label[0] for val_label in val_labels])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:05:53.203568Z","iopub.execute_input":"2024-11-05T09:05:53.203988Z","iopub.status.idle":"2024-11-05T09:05:53.223614Z","shell.execute_reply.started":"2024-11-05T09:05:53.203949Z","shell.execute_reply":"2024-11-05T09:05:53.222596Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0.7710457481449848"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"accuracy_score(sub_category_preds, [val_label[1] for val_label in val_labels])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:06:18.156841Z","iopub.execute_input":"2024-11-05T09:06:18.157215Z","iopub.status.idle":"2024-11-05T09:06:18.176059Z","shell.execute_reply.started":"2024-11-05T09:06:18.157181Z","shell.execute_reply":"2024-11-05T09:06:18.174855Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0.5697966155981423"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"train_category_decoded = le_category.inverse_transform(df_train['category'])\ntrain_category_decoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:23:30.912393Z","iopub.execute_input":"2024-11-05T09:23:30.912747Z","iopub.status.idle":"2024-11-05T09:23:30.923947Z","shell.execute_reply.started":"2024-11-05T09:23:30.912702Z","shell.execute_reply":"2024-11-05T09:23:30.923020Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"array(['Online and Social Media Related Crime', 'Online Financial Fraud',\n       'Online Gambling  Betting', ..., 'Online Financial Fraud',\n       'Online and Social Media Related Crime', 'Online Financial Fraud'],\n      dtype=object)"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"train_category_decoded = list(train_category_decoded)\ntrain_category_decoded = list(set(train_category_decoded))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:25:47.882436Z","iopub.execute_input":"2024-11-05T09:25:47.883255Z","iopub.status.idle":"2024-11-05T09:25:47.892666Z","shell.execute_reply.started":"2024-11-05T09:25:47.883212Z","shell.execute_reply":"2024-11-05T09:25:47.891772Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"df_test = df_test[df_test['category'].isin(train_category_decoded)]\ndf_test['category'] = le_category.transform(df_test['category'])\ndf_test['sub_category'] = le_sub_category.transform(df_test['sub_category'])\n\n# Train-Validation Split\n# train_texts, val_texts, train_labels, val_labels = train_test_split(\n#     df_train['text'].tolist(),\n#     df_train[['category', 'sub_category']].values.tolist(),\n#     test_size=0.2,\n#     random_state=42\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:27:46.358930Z","iopub.execute_input":"2024-11-05T09:27:46.359769Z","iopub.status.idle":"2024-11-05T09:27:46.398429Z","shell.execute_reply.started":"2024-11-05T09:27:46.359728Z","shell.execute_reply":"2024-11-05T09:27:46.397598Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"test_texts = df_test['text'].tolist()\ntest_labels = df_test[['category', 'sub_category']].values.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:29:06.682841Z","iopub.execute_input":"2024-11-05T09:29:06.683255Z","iopub.status.idle":"2024-11-05T09:29:06.710129Z","shell.execute_reply.started":"2024-11-05T09:29:06.683217Z","shell.execute_reply":"2024-11-05T09:29:06.709282Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"test_dataset = CustomDataset(test_texts, test_labels, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:30:02.054451Z","iopub.execute_input":"2024-11-05T09:30:02.054865Z","iopub.status.idle":"2024-11-05T09:30:02.060336Z","shell.execute_reply.started":"2024-11-05T09:30:02.054828Z","shell.execute_reply":"2024-11-05T09:30:02.059417Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"predictions = trainer.predict(test_dataset)\npred_logits = predictions.predictions\n\n# Step 2: Separate logits for category and sub_category\ncategory_logits = pred_logits[0]  # First set of logits for category\nsub_category_logits = pred_logits[1]  # Second set of logits for sub_category\n\n# Step 3: Get the predicted labels by taking the argmax of logits\ncategory_preds = category_logits.argmax(axis=1)\nsub_category_preds = sub_category_logits.argmax(axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:30:33.172205Z","iopub.execute_input":"2024-11-05T09:30:33.172619Z","iopub.status.idle":"2024-11-05T09:33:59.217422Z","shell.execute_reply.started":"2024-11-05T09:30:33.172578Z","shell.execute_reply":"2024-11-05T09:33:59.216688Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"accuracy_score(category_preds, [test_label[0] for test_label in test_labels])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:39:39.493738Z","iopub.execute_input":"2024-11-05T09:39:39.494230Z","iopub.status.idle":"2024-11-05T09:39:39.516275Z","shell.execute_reply.started":"2024-11-05T09:39:39.494176Z","shell.execute_reply":"2024-11-05T09:39:39.515254Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"0.7627330386315587"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"accuracy_score(sub_category_preds, [test_label[1] for test_label in test_labels])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:39:55.148450Z","iopub.execute_input":"2024-11-05T09:39:55.149233Z","iopub.status.idle":"2024-11-05T09:39:55.169085Z","shell.execute_reply.started":"2024-11-05T09:39:55.149191Z","shell.execute_reply":"2024-11-05T09:39:55.168008Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"0.5674610801460696"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}